{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/wkotala/DNN-HW1/blob/main/DNN-homework-1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Project: Multitask Learning for Geometric Shape Classification and Counting**"
      ],
      "metadata": {
        "id": "Z9h7fra7EgSH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Setup"
      ],
      "metadata": {
        "id": "a9NOdqXrJ1JI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wget  https://github.com/marcin119a/data/raw/refs/heads/main/data_gsn.zip\n",
        "!unzip -o data_gsn.zip &> /dev/null\n",
        "!rm data_gsn.zip"
      ],
      "metadata": {
        "id": "cTU8Aa8YJ-kl",
        "ExecuteTime": {
          "end_time": "2025-11-17T21:02:17.207087Z",
          "start_time": "2025-11-17T21:02:15.350983Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO: install all required dependencies"
      ],
      "metadata": {
        "id": "6pbIOQuAxqH_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torchvision.transforms as transforms\n",
        "import sys\n",
        "import plotly.graph_objects as go\n",
        "\n",
        "from pathlib import Path\n",
        "from PIL import Image\n",
        "from torch import Tensor\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from dataclasses import dataclass\n",
        "from typing import Callable, Type\n",
        "from plotly.subplots import make_subplots\n",
        "from IPython.display import display\n",
        "from enum import Enum\n",
        "\n",
        "if \"google.colab\" in sys.modules:\n",
        "    from google.colab import output\n",
        "    output.enable_custom_widget_manager()\n",
        "\n",
        "torch.manual_seed(1)"
      ],
      "metadata": {
        "id": "42PD7mjHKHYe",
        "ExecuteTime": {
          "end_time": "2025-11-17T21:02:19.260919Z",
          "start_time": "2025-11-17T21:02:17.216546Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Exploratory Data Analysis"
      ],
      "metadata": {
        "id": "SXJK9CxAJ1Ml"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data_dir = Path('data')\n",
        "labels_df = pd.read_csv(data_dir / 'labels.csv')\n",
        "labels_df"
      ],
      "metadata": {
        "id": "uMvhwBlHMUzp",
        "ExecuteTime": {
          "end_time": "2025-11-17T21:02:19.342986Z",
          "start_time": "2025-11-17T21:02:19.332534Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "sample_df = labels_df[10:15]\n",
        "shapes = {\n",
        "    'squares': '\\u25A0',\n",
        "    'circles': '\\u25CF',\n",
        "    'up': '\\u25B2',\n",
        "    'right': '\\u25B6',\n",
        "    'down': '\\u25BC',\n",
        "    'left': '\\u25C0',\n",
        "}\n",
        "\n",
        "fig, axes = plt.subplots(1, len(sample_df), figsize=(15, 4))\n",
        "\n",
        "for ax, row in zip(axes, sample_df.itertuples()):\n",
        "    # Plot the image.\n",
        "    img_path = data_dir / row.name\n",
        "    img = Image.open(img_path).convert('L')\n",
        "    ax.imshow(img)\n",
        "\n",
        "    # Display info about shapes in the image.\n",
        "    title_parts = [\n",
        "        f'{count} {shape_symbol}'\n",
        "        for shape_name, shape_symbol in shapes.items()\n",
        "        if (count := getattr(row, shape_name)) > 0\n",
        "    ]\n",
        "    ax.set_title('\\n'.join(title_parts))\n",
        "    ax.axis('off')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "UM7f_fFoWRxb",
        "ExecuteTime": {
          "end_time": "2025-11-17T21:02:19.671387Z",
          "start_time": "2025-11-17T21:02:19.456022Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "plt.title('Counts of Shapes Across Dataset', fontsize=14)\n",
        "labels_df.drop('name', axis=1).sum().rename(shapes).plot.bar(rot=0)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "2PmfFvbzZyJw",
        "ExecuteTime": {
          "end_time": "2025-11-17T21:02:19.800996Z",
          "start_time": "2025-11-17T21:02:19.734447Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "occurrence = (labels_df.drop('name', axis=1) > 0).astype(int)\n",
        "co_occurrence = occurrence.T @ occurrence\n",
        "for i in range(len(co_occurrence)):\n",
        "    co_occurrence.iat[i,i] = 0\n",
        "\n",
        "# Draw a heatmap.\n",
        "plt.title('Number of occurrences for each shape pair', fontsize=14)\n",
        "plt.imshow(co_occurrence, cmap='magma')\n",
        "plt.colorbar()\n",
        "\n",
        "# Label the axes.\n",
        "tick_positions = np.arange(len(co_occurrence.columns))\n",
        "tick_labels = [shapes[name] for name in co_occurrence.columns]\n",
        "plt.xticks(tick_positions, tick_labels, fontsize=14)\n",
        "plt.yticks(tick_positions, tick_labels, fontsize=14, va='center')\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "hmqKDCuCxDT_",
        "ExecuteTime": {
          "end_time": "2025-11-17T21:02:19.935972Z",
          "start_time": "2025-11-17T21:02:19.872771Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO: check how many of each classes are there"
      ],
      "metadata": {
        "id": "ZFzKp3yUNCTT",
        "ExecuteTime": {
          "end_time": "2025-11-17T21:02:20.008780Z",
          "start_time": "2025-11-17T21:02:20.006985Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data pipeline"
      ],
      "metadata": {
        "id": "OGLa5JSGeOW-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Augmentations"
      ],
      "metadata": {
        "id": "hK00dseyQYtu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class RandomTransformator:\n",
        "    \"\"\"\n",
        "    Assumes shapes are in order: squares, circles, up, right, down, left.\n",
        "    \"\"\"\n",
        "\n",
        "    def __call__(self, img: Tensor, counts: Tensor) -> tuple[Tensor, Tensor]:\n",
        "        \"\"\" Performs random transformations. \"\"\"\n",
        "        img, counts = self.horizontal_flip(img, counts, p=0.5)\n",
        "        img, counts = self.vertical_flip(img, counts, p=0.5)\n",
        "        img, counts = self.rotation(img, counts)\n",
        "        return img, counts\n",
        "\n",
        "    def horizontal_flip(self, img: Tensor, counts: Tensor, p: float = 1) -> tuple[Tensor, Tensor]:\n",
        "        \"\"\" Flips image horizontally with probability = p \"\"\"\n",
        "        if torch.rand(1) < p:\n",
        "            img = img.flip(2)\n",
        "            counts[3], counts[5] = counts[5].item(), counts[3].item()\n",
        "\n",
        "        return img, counts\n",
        "\n",
        "    def vertical_flip(self, img: Tensor, counts: Tensor, p: float = 1) -> tuple[Tensor, Tensor]:\n",
        "        \"\"\" Flips image vertically with probability = p \"\"\"\n",
        "        if torch.rand(1) < p:\n",
        "            img = img.flip(1)\n",
        "            counts[2], counts[4] = counts[4].item(), counts[2].item()\n",
        "\n",
        "        return img, counts\n",
        "\n",
        "    def rotation(self, img: Tensor, counts: Tensor) -> tuple[Tensor, Tensor]:\n",
        "        \"\"\" Rotates image by random angle from: 0, pi/2, pi, -pi/2 \"\"\"\n",
        "        k = torch.randint(-1, 3, size=(1,)).item()\n",
        "        img = img.rot90(k=k, dims=(1,2))\n",
        "\n",
        "        triangles_shifted = torch.roll(counts[2:], -k)\n",
        "        counts[2:] = triangles_shifted\n",
        "\n",
        "        return img, counts"
      ],
      "metadata": {
        "id": "SwQ4q-dFQ_1A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Dataset"
      ],
      "metadata": {
        "id": "O_PTfH0mQaPL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class GSNDataset(Dataset):\n",
        "    \"\"\"\n",
        "    Custom PyTorch Dataset for the Geometric Shape Numbers (GSN) dataset.\n",
        "\n",
        "    GSNDataset handles two tasks:\n",
        "    1. Classification: Identifying which of the 135 possible shape-pair\n",
        "       and count-split configurations is present in the image.\n",
        "    2. Regression: Predicting the count of 6 different shape types.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, data_dir: Path, train: bool, train_val_split: float = 0.9, transform: Callable | None = None):\n",
        "        \"\"\"\n",
        "        Input:\n",
        "        - data_dir: Path to the directory containing 'labels.csv' and all the images.\n",
        "        - train: A boolean indicating whether to create train or validation dataset.\n",
        "        - train_val_split: Fraction specifying what percentage of data is train data; the rest is validation data.\n",
        "        - transform: Optional transform to be applied on a sample.\n",
        "                     transform should implement __call__(image, counts) -> (transformed_image, transformed_counts),\n",
        "                     where images is a tensor of shape (C=1, H=28, W=28),\n",
        "                     and counts is a tensor of shape (6,), with count of shapes in the same order as in self.shape_names()\n",
        "        \"\"\"\n",
        "        self.data_dir = data_dir\n",
        "        self.transform = transform\n",
        "\n",
        "        all_labels_df = pd.read_csv(data_dir / 'labels.csv')\n",
        "        train_len = round(len(all_labels_df) * train_val_split)\n",
        "\n",
        "        if train:\n",
        "            self.labels_df = all_labels_df[:train_len].reset_index(drop=True)\n",
        "        else:\n",
        "            self.labels_df = all_labels_df[train_len:].reset_index(drop=True)\n",
        "\n",
        "        self.shape_columns = list(self.labels_df.drop('name', axis=1).columns)\n",
        "\n",
        "        self._pair_to_id = dict()\n",
        "        pair_id = 0\n",
        "        for i in range(len(self.shape_columns)):\n",
        "            for j in range(i + 1, len(self.shape_columns)):\n",
        "                self._pair_to_id[(i, j)] = pair_id\n",
        "                pair_id += 1\n",
        "\n",
        "    def shape_names(self) -> list[str]:\n",
        "        \"\"\"\n",
        "        Returns list of shape names used in dataset.\n",
        "        Order of the shapes in this list dictates:\n",
        "        - Order of count labels for regression model.\n",
        "        - Class labels for classification model:\n",
        "            - classes 0...8 contain shapes list[0], list[1]\n",
        "            - classes 9...17 contain shapes list[0], list[2],\n",
        "            ...\n",
        "            - classes 36...44 contain shapes list[0], list[5],\n",
        "            - classes 45...53 contain shapes list[1], list[2],\n",
        "            ...\n",
        "            - classes 126...134 contain shapes list[4], list[5].\n",
        "        \"\"\"\n",
        "        return self.shape_columns\n",
        "\n",
        "    def _calculate_class_from_shapes_counts(self, counts: Tensor) -> Tensor:\n",
        "        \"\"\"\n",
        "        Translates shape configurations into unique class labels.\n",
        "\n",
        "        Input: counts of each shape in an image as tensor of shape (6,)\n",
        "        Output: class label, i.e. integer in [0, 134], as Tensor\n",
        "        \"\"\"\n",
        "        nonzero_indices = torch.nonzero(counts, as_tuple=True)[0]\n",
        "        assert len(nonzero_indices) == 2\n",
        "        assert counts[nonzero_indices].sum() == 10\n",
        "\n",
        "        pair = tuple(nonzero_indices.tolist())\n",
        "        assert pair in self._pair_to_id\n",
        "        return self._pair_to_id[pair] * 9 + counts[pair[0]] - 1\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.labels_df)\n",
        "\n",
        "    def __getitem__(self, idx: int) -> tuple[Tensor, Tensor, Tensor]:\n",
        "        \"\"\"\n",
        "        Output:\n",
        "        - image as tensor of shape (C=1, H=28, W=28)\n",
        "        - class label as tensor of shape (1,)\n",
        "        - true counts as tensor of shape (6,)\n",
        "        \"\"\"\n",
        "        row = self.labels_df.iloc[idx]\n",
        "        img_path = self.data_dir / row['name']\n",
        "        img = Image.open(img_path).convert('L')\n",
        "        img_tensor = transforms.functional.to_tensor(img)\n",
        "\n",
        "        counts = torch.tensor(row[self.shape_columns].astype(np.float32).to_numpy(), dtype=torch.float32)\n",
        "\n",
        "        if self.transform:\n",
        "            img_tensor, counts = self.transform(img_tensor, counts)\n",
        "\n",
        "        class_label = self._calculate_class_from_shapes_counts(counts).to(torch.long)\n",
        "\n",
        "        return img_tensor, class_label, counts\n",
        "\n",
        "# TODO: check if transformations dont compute gradients\n",
        "\n",
        "# TODO: change shape_columns in __init__ if doesn't match expectations"
      ],
      "metadata": {
        "id": "LZm_FxPzSv5O",
        "ExecuteTime": {
          "end_time": "2025-11-17T21:02:20.082220Z",
          "start_time": "2025-11-17T21:02:20.077549Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model architecture"
      ],
      "metadata": {
        "id": "lU3ElGtVeSte"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class MultitaskModel(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "\n",
        "        self.backbone = nn.Sequential(\n",
        "            nn.Conv2d(1, 8, 3, stride=1, padding=1), nn.ReLU(), # (B, 8, H, W)\n",
        "            nn.Conv2d(8, 16, 3, stride=1, padding=1), nn.ReLU(), # (B, 16, H, W)\n",
        "            nn.Conv2d(16, 32, 3, stride=1, padding=1), nn.ReLU(), # (B, 32, H, W)\n",
        "            nn.Conv2d(32, 64, 3, stride=1, padding=1), nn.ReLU(), # (B, 64, H, W)\n",
        "            nn.Flatten(start_dim=1), # (B, 64 * H * W)\n",
        "            nn.Linear(64 * 28 * 28, 256), nn.ReLU() # (B, 256)\n",
        "        )\n",
        "\n",
        "        # TODO: experiment with the heads\n",
        "\n",
        "        self.head_cls = nn.Sequential(\n",
        "            nn.Linear(256, 256), # (B, 256)\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(),\n",
        "            nn.Linear(256, 135), # (B, 135)\n",
        "            nn.LogSoftmax(dim=1)\n",
        "        )\n",
        "\n",
        "        self.head_cnt = nn.Sequential(\n",
        "            nn.Linear(256, 128), # (B, 128)\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(),\n",
        "            nn.Linear(128, 6), # (B, 6)\n",
        "        )\n",
        "\n",
        "    def forward(self, x: Tensor) -> tuple[Tensor, Tensor]:\n",
        "        \"\"\"\n",
        "        Input shape: (B, 1, H, W).\n",
        "        Output:\n",
        "        - classification log-probabilities (B, 135)\n",
        "        - regression counts (B, 6)\n",
        "        \"\"\"\n",
        "        features = self.backbone(x)\n",
        "        log_probs = self.head_cls(features)\n",
        "        counts = self.head_cnt(features)\n",
        "        return log_probs, counts"
      ],
      "metadata": {
        "id": "Jvn_RselxAw0",
        "ExecuteTime": {
          "end_time": "2025-11-17T21:02:20.128928Z",
          "start_time": "2025-11-17T21:02:20.125716Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training & Evaluation"
      ],
      "metadata": {
        "id": "2wQJh0qY8hXh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Setup"
      ],
      "metadata": {
        "id": "PBZ0sxh_-NF2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "@dataclass\n",
        "class TrainingSettings:\n",
        "    device: torch.device\n",
        "\n",
        "    learning_rate: float = 1e-3\n",
        "    max_epochs: int = 100\n",
        "    train_batch_size: int = 64\n",
        "\n",
        "    cls_loss_fn: Callable = F.nll_loss        # classification loss function\n",
        "    lambda_cls: float = 1.0                   # weight of classification loss function\n",
        "    cnt_loss_fn: Callable = F.smooth_l1_loss  # regression loss function\n",
        "    lambda_cnt: float = 1.0                   # weight of regression loss function\n",
        "\n",
        "    early_stop_patience: int = 10\n",
        "\n",
        "    optimizer: Type[torch.optim.Optimizer] = torch.optim.Adam"
      ],
      "metadata": {
        "id": "Op2Hcgpq8n59",
        "ExecuteTime": {
          "end_time": "2025-11-17T21:02:20.176638Z",
          "start_time": "2025-11-17T21:02:20.172967Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Evaluation"
      ],
      "metadata": {
        "id": "cOb1geOx_Cu-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class ClassificationMetricsCalculator:\n",
        "    \"\"\"\n",
        "    Calculates classification metrics.\n",
        "    Each method follows the convention:\n",
        "    Input:\n",
        "    - predicted classes as tensor of shape (B,)\n",
        "    - actual classes as tensor of shape (B,)\n",
        "    Output:\n",
        "    - calculated metric as float\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, eps: float = 1e-8):\n",
        "        self.n_classes = 135\n",
        "        self.eps = eps\n",
        "\n",
        "    def top_1_accuracy(self, pred_class: Tensor, actual_class: Tensor) -> float:\n",
        "        return (pred_class == actual_class).to(torch.float32).mean().item()\n",
        "\n",
        "    def macro_f1(self, pred_class: Tensor, actual_class: Tensor) -> float:\n",
        "        tp = torch.zeros(self.n_classes, device=pred_class.device)\n",
        "        fp = torch.zeros(self.n_classes, device=pred_class.device)\n",
        "        fn = torch.zeros(self.n_classes, device=pred_class.device)\n",
        "\n",
        "        for i in range(self.n_classes):\n",
        "            tp[i] = ((pred_class == i) & (actual_class == i)).sum()\n",
        "            fp[i] = ((pred_class == i) & (actual_class != i)).sum()\n",
        "            fn[i] = ((pred_class != i) & (actual_class == i)).sum()\n",
        "\n",
        "        f1 = 2 * tp / (2 * tp + fp + fn + self.eps)\n",
        "\n",
        "        classes_present = (tp + fn) > 0\n",
        "        f1 = f1[classes_present]\n",
        "        return f1.mean().item()\n",
        "\n",
        "\n",
        "    def per_pair_accuracy(self, pred_class: Tensor, actual_class: Tensor) -> float:\n",
        "        per_pair_accuracy_sum = 0.0\n",
        "        num_pairs_present = 0\n",
        "\n",
        "        for i in range(0, self.n_classes, 9):\n",
        "            mask = (i <= actual_class) & (actual_class <= i + 8)\n",
        "            if mask.any():\n",
        "                per_pair_accuracy_sum += self.top_1_accuracy(pred_class[mask], actual_class[mask])\n",
        "                num_pairs_present += 1\n",
        "\n",
        "        per_pair_accurace_average = per_pair_accuracy_sum / num_pairs_present if num_pairs_present > 0 else float('nan')\n",
        "        return per_pair_accurace_average\n",
        "\n",
        "class RegressionMetricsCalculator:\n",
        "    \"\"\"\n",
        "    Calculates regression metrics.\n",
        "    Each method follows the convention:\n",
        "    Input:\n",
        "    - predicted counts as tensor of shape (B, 6)\n",
        "    - actual counts as tensor of shape (B, 6)\n",
        "    Output:\n",
        "    - calculated per-class metric as tensor of shape (6,)\n",
        "    - calculated overall metric as tensor of shape (6,)\n",
        "    \"\"\"\n",
        "\n",
        "    def mae_per_class(self, pred_counts: Tensor, actual_counts: Tensor) -> Tensor:\n",
        "        absolute_error = torch.abs(pred_counts - actual_counts)\n",
        "        return absolute_error.mean(dim=0)\n",
        "\n",
        "    def mae(self, pred_counts: Tensor, actual_counts: Tensor) -> float:\n",
        "        absolute_error = torch.abs(pred_counts - actual_counts)\n",
        "        return absolute_error.mean().item()\n",
        "\n",
        "    def rmse_per_class(self, pred_counts: Tensor, actual_counts: Tensor) -> Tensor:\n",
        "        squared_error = torch.square(pred_counts - actual_counts)\n",
        "        return torch.sqrt(squared_error.mean(dim=0))\n",
        "\n",
        "    def rmse(self, pred_counts: Tensor, actual_counts: Tensor) -> float:\n",
        "        squared_error = torch.square(pred_counts - actual_counts)\n",
        "        return torch.sqrt(squared_error.mean()).item()\n",
        "\n",
        "\n",
        "class MetricsCalculator:\n",
        "    def __init__(self):\n",
        "        self.cls = ClassificationMetricsCalculator()\n",
        "        self.cnt = RegressionMetricsCalculator()\n",
        "\n",
        "# TODO: revisit this implementation\n",
        "\n",
        "\n",
        "# TODO: pretty presentation of those metrics\n",
        "\n",
        "# TODO: rmse and mae overall - what do they mean???\n",
        "# TODO: per-pair accuracy: one or six results\n",
        "\n",
        "# TODO: change all \"\" to '' everywhere in notebook"
      ],
      "metadata": {
        "id": "MFH8FF1Q90bn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class TraceName(str, Enum):\n",
        "    TRAIN_CLS = 'train cls loss'\n",
        "    TRAIN_CNT = 'train cnt loss'\n",
        "    TRAIN_LOSS = 'train loss'\n",
        "\n",
        "    VAL_CLS = 'val cls loss'\n",
        "    VAL_CNT = 'val cnt los'\n",
        "    VAL_LOSS = 'val loss'\n",
        "    VAL_ACC = 'val accuracy'\n",
        "    VAL_RMSE = 'val RMSE'\n",
        "\n",
        "class TrainingVisualizer:\n",
        "    def __init__(self):\n",
        "        \"\"\"\n",
        "            Defines layout of the training dashboard and displays empty plots.\n",
        "        \"\"\"\n",
        "\n",
        "        # Data that will be visualized.\n",
        "        self.data = {trace_name: [] for trace_name in TraceName}\n",
        "\n",
        "        # Layout.\n",
        "        plots = make_subplots(\n",
        "            rows=2, cols=3,\n",
        "            specs=[[{\"colspan\": 3}, None, None],\n",
        "                   [{}, {}, {}]],\n",
        "            subplot_titles=(\"Training Losses\", \"Validation Losses\", \"Validation Accuracy\", \"Validation RMSE\"),\n",
        "        ).update_layout(\n",
        "            template='plotly_dark',\n",
        "            height=800,\n",
        "            title_text=\"Training Dashboard\"\n",
        "        )\n",
        "\n",
        "        plots.update_xaxes(title_text='Epoch')\n",
        "        plots.update_yaxes(title_text=\"Average Loss Value\", col=1)\n",
        "        plots.update_yaxes(title_text=\"Accuracy %\", row=2, col=2)\n",
        "        plots.update_yaxes(title_text=\"RMSE Value\", row=2, col=3)\n",
        "\n",
        "        # Traces.\n",
        "        train_losses_pos = {'row': 1, 'col': 1}\n",
        "        val_losses_pos = {'row': 2, 'col': 1}\n",
        "\n",
        "        traces_config = [ # list  of tuples (name, position)\n",
        "            (TraceName.TRAIN_CLS, train_losses_pos),\n",
        "            (TraceName.TRAIN_CNT, train_losses_pos),\n",
        "            (TraceName.TRAIN_LOSS, train_losses_pos),\n",
        "            (TraceName.VAL_CLS, val_losses_pos),\n",
        "            (TraceName.VAL_CNT, val_losses_pos),\n",
        "            (TraceName.VAL_LOSS, val_losses_pos),\n",
        "            (TraceName.VAL_ACC, {'row': 2, 'col': 2}),\n",
        "            (TraceName.VAL_RMSE, {'row': 2, 'col': 3})\n",
        "        ]\n",
        "\n",
        "        for name, pos in traces_config:\n",
        "            plots.add_trace(go.Scatter(name=name), **pos)\n",
        "\n",
        "        # Display the plots as widget that will be updated each epoch.\n",
        "        self.plots = go.FigureWidget(plots)\n",
        "        self.traces = {trace.name: trace for trace in self.plots.data}\n",
        "        display(self.plots)\n",
        "\n",
        "    def _update_plot(self, updates: dict[TraceName, float], curr_len: int):\n",
        "        with self.plots.batch_update():\n",
        "            new_len = curr_len + 1\n",
        "            x_axis = list(range(1, new_len + 1))\n",
        "\n",
        "            for trace_name, value in updates.items():\n",
        "                self.data[trace_name].append(value)\n",
        "                self.traces[trace_name].x = x_axis\n",
        "                self.traces[trace_name].y = self.data[trace_name]\n",
        "\n",
        "    def plot_train(self, cls_loss: float, cnt_loss: float, loss: float):\n",
        "        \"\"\"\n",
        "        Updates the dashboard with data from train phase.\n",
        "        \"\"\"\n",
        "        self._update_plot({\n",
        "            TraceName.TRAIN_CLS: cls_loss,\n",
        "            TraceName.TRAIN_CNT: cnt_loss,\n",
        "            TraceName.TRAIN_LOSS: loss\n",
        "\n",
        "        }, len(self.data[TraceName.TRAIN_LOSS]))\n",
        "\n",
        "    def plot_val(self, cls_loss: float, cnt_loss: float, loss: float, accuracy: float, rmse: float):\n",
        "        \"\"\"\n",
        "        Updates the dashboard with data from validation phase.\n",
        "        \"\"\"\n",
        "        self._update_plot({\n",
        "            TraceName.VAL_CLS: cls_loss,\n",
        "            TraceName.VAL_CNT: cnt_loss,\n",
        "            TraceName.VAL_LOSS: loss,\n",
        "            TraceName.VAL_ACC: accuracy * 100, # convert to %\n",
        "            TraceName.VAL_RMSE: rmse\n",
        "\n",
        "        }, len(self.data[TraceName.VAL_LOSS]))"
      ],
      "metadata": {
        "id": "kDaD6ZI8-B7g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate(model: nn.Module, loader: DataLoader, settings: TrainingSettings, calc: MetricsCalculator, visualizer: TrainingVisualizer) -> None:\n",
        "    model.eval()\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for images, class_labels, counts in loader:\n",
        "            images = images.to(settings.device)\n",
        "            class_labels = class_labels.to(settings.device)\n",
        "            counts = counts.to(settings.device)\n",
        "\n",
        "            log_probs, pred_counts = model(images)\n",
        "\n",
        "            cls_loss = settings.cls_loss_fn(log_probs, class_labels)\n",
        "            cnt_loss = settings.cnt_loss_fn(pred_counts, counts)\n",
        "            loss = settings.lambda_cls * cls_loss + settings.lambda_cnt * cnt_loss\n",
        "\n",
        "            pred_class = torch.argmax(log_probs, dim=1)\n",
        "\n",
        "        accuracy = calc.cls.top_1_accuracy(pred_class, class_labels)\n",
        "        rmse = calc.cnt.rmse(pred_counts, counts)\n",
        "        visualizer.plot_val(cls_loss.item(), cnt_loss.item(), loss.item(), accuracy, rmse)\n",
        "\n",
        "    return loss.item() # TODO: make it not assume batch size = len(dataset)"
      ],
      "metadata": {
        "id": "VxxEX3Lb_aBY",
        "ExecuteTime": {
          "end_time": "2025-11-17T21:02:20.224831Z",
          "start_time": "2025-11-17T21:02:20.220975Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training"
      ],
      "metadata": {
        "id": "Nu1We72--96c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train_epoch(model: nn.Module, loader: DataLoader, optimizer: torch.optim.Optimizer, settings: TrainingSettings, visualizer: TrainingVisualizer) -> None:\n",
        "    model.train()\n",
        "    total_correct = 0\n",
        "    total_cls_loss = 0.0\n",
        "    total_cnt_loss = 0.0\n",
        "\n",
        "    for images, class_labels, counts in loader:\n",
        "        images = images.to(settings.device)\n",
        "        class_labels = class_labels.to(settings.device)\n",
        "        counts = counts.to(settings.device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        log_probs, pred_counts = model(images)\n",
        "\n",
        "        cls_loss = settings.cls_loss_fn(log_probs, class_labels)\n",
        "        cnt_loss = settings.cnt_loss_fn(pred_counts, counts)\n",
        "        loss = settings.lambda_cls * cls_loss + settings.lambda_cnt * cnt_loss\n",
        "\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # TODO: this should be visualizer's task probably\n",
        "        with torch.no_grad():\n",
        "            pred_class = torch.argmax(log_probs, dim=1)\n",
        "            total_correct += (pred_class == class_labels).sum().item()\n",
        "            total_cls_loss += cls_loss.item()\n",
        "            total_cnt_loss += cnt_loss.item()\n",
        "\n",
        "\n",
        "    avg_cls_loss = total_cls_loss / len(loader)\n",
        "    avg_cnt_loss = total_cnt_loss / len(loader)\n",
        "    avg_total_loss = settings.lambda_cls * avg_cls_loss + settings.lambda_cnt * avg_cnt_loss\n",
        "    print(f'Classification loss: {avg_cls_loss}')\n",
        "    print(f'Regression loss: {avg_cnt_loss}')\n",
        "    print(f'Total loss: {avg_total_loss}')\n",
        "    print(f'Accuracy: {total_correct / len(loader.dataset) * 100  :.2f}%')"
      ],
      "metadata": {
        "id": "BLcP5yjULgwV",
        "ExecuteTime": {
          "end_time": "2025-11-17T21:02:20.272707Z",
          "start_time": "2025-11-17T21:02:20.269907Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "class EarlyStopper:\n",
        "    def __init__(self, patience=5):\n",
        "        self.patience = patience\n",
        "        self.counter = 0\n",
        "        self.best_loss = float('inf')\n",
        "\n",
        "    def __call__(self, val_loss):\n",
        "        if val_loss < self.best_loss\n",
        "            self.best_loss = val_loss\n",
        "            self.counter = 0\n",
        "            return False\n",
        "        else:\n",
        "            self.counter += 1\n",
        "            if self.counter >= self.patience:\n",
        "                return True\n",
        "            return False\n",
        "\n",
        "# TODO: TrainingReporter\n",
        "\n",
        "def train_loop(model: nn.Module, train_loader: DataLoader, val_loader: DataLoader, settings: TrainingSettings, calc: MetricsCalculator, visualizer: TrainingVisualizer) -> None:\n",
        "    optimizer = settings.optimizer(model.parameters(), lr=settings.learning_rate)\n",
        "    early_stopper = EarlyStopper(patience=settings.early_stop_patience)\n",
        "\n",
        "    for epoch in range(settings.max_epochs):\n",
        "        print(f'Epoch {epoch + 1}')\n",
        "        train_epoch(model, train_loader, optimizer, settings, visualizer)\n",
        "        val_loss = evaluate(model, val_loader, settings, calc, visualizer)\n",
        "\n",
        "        if early_stopper(val_loss):\n",
        "            print(f\"Early stopping triggered!\")\n",
        "            break\n",
        "\n",
        "        print()"
      ],
      "metadata": {
        "id": "KcB33aUsOfyl",
        "ExecuteTime": {
          "end_time": "2025-11-17T21:02:20.327199Z",
          "start_time": "2025-11-17T21:02:20.324356Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Experiments"
      ],
      "metadata": {
        "id": "haCQqSB1_Qz3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data_dir = Path('data')\n",
        "transformator = RandomTransformator()\n",
        "train_dataset = GSNDataset(data_dir, train=True, transform=transformator)\n",
        "val_dataset = GSNDataset(data_dir, train=False, transform=None)\n",
        "\n",
        "use_cuda = torch.cuda.is_available()\n",
        "device = torch.device('cuda' if use_cuda else 'cpu')\n",
        "settings = TrainingSettings(device=device)\n",
        "\n",
        "\n",
        "kwargs = {\"num_workers\": 2, \"pin_memory\": True} if use_cuda else {}\n",
        "train_loader = DataLoader(train_dataset, batch_size=settings.train_batch_size, shuffle=True, **kwargs)\n",
        "val_loader = DataLoader(val_dataset, batch_size=len(val_dataset), **kwargs)\n",
        "\n",
        "model = MultitaskModel().to(device)\n",
        "\n",
        "calc = MetricsCalculator()\n",
        "visualizer = TrainingVisualizer()\n",
        "\n",
        "# TODO: actually make the experiments"
      ],
      "metadata": {
        "id": "Y9u1Kzu0P-E8",
        "ExecuteTime": {
          "end_time": "2025-11-17T21:02:21.043733Z",
          "start_time": "2025-11-17T21:02:20.373321Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "train_loop(model, train_loader, val_loader, settings, calc, visualizer)"
      ],
      "metadata": {
        "id": "cKMm3PIASUZW",
        "ExecuteTime": {
          "end_time": "2025-11-17T21:02:21.264868Z",
          "start_time": "2025-11-17T21:02:21.055179Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "sJ_NrKD2u3u4"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}